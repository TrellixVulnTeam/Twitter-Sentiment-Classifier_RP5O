{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\Avyakta\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training data\n",
    "data = pd.read_csv('data_twitter_sentiment/semeval_train.txt',sep='\\t',names=[\"sentiment\",\"tweet\"])\n",
    "# data.head()\n",
    "# reading test data\n",
    "dt1 = pd.read_csv('data_twitter_sentiment/Twitter2013_raw.txt',sep='\\t',names=[\"sentiment\",\"tweet\"])\n",
    "dt2 = pd.read_csv('data_twitter_sentiment/Twitter2014_raw.txt',sep='\\t',names=[\"sentiment\",\"tweet\"])\n",
    "dt3 = pd.read_csv('data_twitter_sentiment/Twitter2015_raw.txt',sep='\\t',names=[\"sentiment\",\"tweet\"])\n",
    "dt4 = pd.read_csv('data_twitter_sentiment/Twitter2016_raw.txt',sep='\\t',names=[\"sentiment\",\"tweet\"])\n",
    "\n",
    "# dt = pd.concat([dt1, dt2, dt3, dt4])\n",
    "dt = dt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "neutral     4099\n",
       "positive    3227\n",
       "negative    1262\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(features):\n",
    "    processed_features = []\n",
    "    for sentence in range(0, len(features)):\n",
    "        # remove hyperlinks, tags, hashtags\n",
    "        processed_feature = ' ' + str(features[sentence]) + ' '\n",
    "        processed_feature = re.sub(r'http*\\S+', ' ', processed_feature) \n",
    "        processed_feature = re.sub(r'https*\\S+', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'@\\S+', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'#\\S+', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'\\bhm*\\s+', '', processed_feature)\n",
    "        \n",
    "        # remove all digits\n",
    "        processed_feature = re.sub(r'[0-9]', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'[_]', ' ', processed_feature)\n",
    "        \n",
    "        # Remove all the special characters\n",
    "        processed_feature = re.sub(r'\\W', ' ', processed_feature)\n",
    "        \n",
    "        # remove all single characters\n",
    "        processed_feature= re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
    "\n",
    "        # Remove single characters from the start\n",
    "        processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature) \n",
    "\n",
    "        # Substituting multiple spaces with single space\n",
    "        processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
    "\n",
    "        # Converting to Lowercase\n",
    "        processed_feature = processed_feature.lower()\n",
    "\n",
    "        # remove some meaningless words\n",
    "        processed_feature = re.sub(r'(\\s)aa\\w+', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'(\\s)ba(\\s)', ' ', processed_feature)\n",
    "        processed_feature = re.sub(r'(\\s)th(\\s)', ' ', processed_feature)\n",
    "\n",
    "        processed_features.append(processed_feature)\n",
    "    return processed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8588, 17797)\n",
      "Sparsity of training features is  99.92719082901486 %\n"
     ]
    }
   ],
   "source": [
    "# data cleaning\n",
    "train_features = preprocess(data.iloc[:, 1].values)\n",
    "test_features = preprocess(dt.iloc[:, 1].values)\n",
    "\n",
    "# vectorizing data\n",
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=2, max_df=0.95, norm = 'l2',ngram_range=(1, 4)).fit(train_features)\n",
    "# v = vectorizer\n",
    "cv_array = vectorizer.transform(train_features).toarray()\n",
    "cvt_array = vectorizer.transform(test_features).toarray()\n",
    "\n",
    "print( cv_array.shape, sep='\\n')\n",
    "sparsity = 1.0 - ( np.count_nonzero(cv_array) / float(cv_array.size) )\n",
    "print('Sparsity of training features is ', sparsity*100, '%')\n",
    "\n",
    "# ch2 = SelectKBest(chi2, k=500)\n",
    "# cv_array = ch2.fit_transform(cv_array, data['sentiment'])\n",
    "# cvt_array = ch2.transform(cvt_array)\n",
    "\n",
    "# svd = TruncatedSVD(n_components=300, random_state=42)\n",
    "# s = svd.fit(cv_array)\n",
    "# cv_array = s.transform(cv_array) \n",
    "# cvt_array = s.transform(cvt_array)\n",
    "\n",
    "# label encoding\n",
    "lab_enc = preprocessing.LabelEncoder().fit(data['sentiment'])\n",
    "\n",
    "x_train = cv_array\n",
    "label_train = data['sentiment']\n",
    "y_train = lab_enc.transform(label_train)\n",
    "\n",
    "x_test = cvt_array\n",
    "label_test = dt['sentiment']\n",
    "y_test = lab_enc.transform(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      " positive Label Most correlated unigrams for:\n",
      ". amazing\n",
      ". thanks\n",
      ". fun\n",
      ". best\n",
      ". wait\n",
      ". excited\n",
      ". great\n",
      ". happy\n",
      ". love\n",
      ". good\n",
      " positive Label Most correlated bigrams:\n",
      ". celebrity juice\n",
      ". good night\n",
      ". great day\n",
      ". sm bacolod\n",
      ". happy friday\n",
      ". good day\n",
      ". good morning\n",
      ". looking forward\n",
      ". good luck\n",
      ". happy birthday\n",
      "\n",
      " negative Label Most correlated unigrams for:\n",
      ". didn\n",
      ". stupid\n",
      ". sorry\n",
      ". hate\n",
      ". don\n",
      ". worse\n",
      ". sad\n",
      ". shit\n",
      ". bad\n",
      ". fuck\n",
      " negative Label Most correlated bigrams:\n",
      ". cancelled tomorrow\n",
      ". watching game\n",
      ". really don\n",
      ". tv time\n",
      ". feel bad\n",
      ". breakout kings\n",
      ". don like\n",
      ". nets game\n",
      ". don wanna\n",
      ". don want\n",
      "\n",
      " neutral Label Most correlated unigrams for:\n",
      ". hope\n",
      ". thanks\n",
      ". fun\n",
      ". best\n",
      ". excited\n",
      ". wait\n",
      ". great\n",
      ". love\n",
      ". happy\n",
      ". good\n",
      " neutral Label Most correlated bigrams:\n",
      ". sm bacolod\n",
      ". white arrows\n",
      ". good day\n",
      ". daily zap\n",
      ". happy friday\n",
      ". george clooney\n",
      ". good morning\n",
      ". good luck\n",
      ". looking forward\n",
      ". happy birthday\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "N = 10\n",
    "labels = ['positive', 'negative', 'neutral']\n",
    "\n",
    "for i in range(0,3):\n",
    "    features_chi2 = chi2(cv_array, data['sentiment'] == labels[i])\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(vectorizer.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"\\n {} Label Most correlated unigrams for:\\n. {}\".format(labels[i],'\\n. '.join(unigrams[-N:])))\n",
    "    print(\" {} Label Most correlated bigrams:\\n. {}\".format(labels[i],'\\n. '.join(bigrams[-N:])))\n"
   ]
  },
  {
   "source": [
    "Training Data with evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy:  0.889\nTest accuracy:  0.644\nF1:  0.624\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "lr = LogisticRegression(solver = 'newton-cg', random_state = 1, max_iter=500, penalty = 'l2', C = 1.8)\n",
    "lr.fit(x_train, y_train)\n",
    "y_train_pred = lr.predict(x_train)\n",
    "y_pred = lr.predict(x_test)\n",
    "\n",
    "print(\"Train accuracy: \",round(metrics.accuracy_score(y_train,y_train_pred),3))\n",
    "print(\"Test accuracy: \",round(metrics.accuracy_score(y_test,y_pred),3))\n",
    "print(\"F1: \",round(metrics.f1_score(y_test, y_pred, average = 'weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy Linear Kernel: 0.8557289240801118\n",
      "Test Accuracy Linear Kernel: 0.6419202518363064\n",
      "F1 Score Linear Kernel:  0.621\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "# rbf = svm.SVC(kernel='rbf', gamma=1, C=5, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "# sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(x_train, y_train)\n",
    "\n",
    "linear_pred = linear.predict(x_test)\n",
    "\n",
    "print('Train Accuracy Linear Kernel:',linear.score(x_train, y_train))\n",
    "print('Test Accuracy Linear Kernel:', linear.score(x_test, y_test))\n",
    "print(\"F1 Score Linear Kernel: \",round(metrics.f1_score(y_test, linear_pred, average = 'weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy:  0.854\n",
      "Train F1:  0.85\n",
      "[[ 144  359   98]\n",
      " [  38 1398  203]\n",
      " [  48  583  941]]\n",
      "Test accuracy: 0.6513641133263379\n",
      "Test F1:  0.633\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "text_classifier = RandomForestClassifier(n_estimators=50, random_state=0, max_depth=400, max_features = 900, min_samples_leaf = 2)\n",
    "text_classifier.fit(x_train, label_train)\n",
    "\n",
    "predictions = text_classifier.predict(x_test)\n",
    "y_train_pred = text_classifier.predict(x_train)\n",
    "\n",
    "print(\"Train accuracy: \",round(accuracy_score(label_train,y_train_pred),3))\n",
    "print(\"Train F1: \",round(f1_score(label_train, y_train_pred, average = 'weighted'),3))\n",
    "\n",
    "print(confusion_matrix(label_test,predictions))\n",
    "# print(classification_report(label_test,predictions))\n",
    "print('Test accuracy: {}'.format(accuracy_score(label_test, predictions)))\n",
    "print(\"Test F1: \",round(f1_score(label_test, predictions, average = 'weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train accuracy:  0.841\n              precision    recall  f1-score   support\n\n    negative       0.53      0.29      0.37       601\n     neutral       0.60      0.69      0.64      1639\n    positive       0.65      0.65      0.65      1572\n\n    accuracy                           0.61      3812\n   macro avg       0.59      0.54      0.55      3812\nweighted avg       0.61      0.61      0.60      3812\n\nTest accuracy: 0.6114900314795383\nTest F1:  0.602\n"
     ]
    }
   ],
   "source": [
    "#  Naive Bayes Classifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "mnb = MultinomialNB(class_prior = [50, 40, 40])\n",
    "mnb.fit(x_train, label_train)\n",
    "\n",
    "predictions = mnb.predict(x_test)\n",
    "y_train_pred = mnb.predict(x_train)\n",
    "\n",
    "print(\"Train accuracy: \",round(accuracy_score(label_train,y_train_pred),3))\n",
    "# print(confusion_matrix(label_test,predictions))\n",
    "print(classification_report(label_test,predictions))\n",
    "print('Test accuracy: {}'.format(accuracy_score(label_test, predictions)))\n",
    "print(\"Test F1: \",round(f1_score(label_test, predictions, average = 'weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "param_grid = {'n_neighbors': np.arange(24, 30)}\n",
    "#use gridsearch to test all values for n_neighbors\n",
    "knn_gscv = GridSearchCV(knn, param_grid, cv=5)\n",
    "knn_gscv.fit(x_train,label_train)\n",
    "predictions = knn_gscv.predict(x_test)\n",
    "y_train_pred = knn_gscv.predict(x_train)\n",
    "\n",
    "print(\"Train accuracy: {}\",round(accuracy_score(label_train,y_train_pred),3))\n",
    "\n",
    "# print(confusion_matrix(label_test,predictions))\n",
    "print(classification_report(label_test,predictions))\n",
    "print('Test accuracy: '.format(accuracy_score(label_test, predictions)))\n",
    "print(\"Test F1: \",round(f1_score(label_test, predictions, average = 'weighted'),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check top performing n_neighbors value\n",
    "knn_gscv.best_params_"
   ]
  }
 ]
}
